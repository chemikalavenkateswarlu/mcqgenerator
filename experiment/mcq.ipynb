{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ebaa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed40660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5312e31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # take environment v ariables from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3296a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d902030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a16b26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (1.1.6)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.2 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-openai) (1.2.5)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-openai) (2.14.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.5.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.2->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.2->langchain-openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.2->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-openai) (2.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\mcqgenerator\\env\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bd2a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# Initialize the LLM\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",     # or gpt-3.5-turbo if enabled in your account\n",
    "    temperature=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd06a536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x00000251F5F5CB90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000251F5F5CF50>, root_client=<openai.OpenAI object at 0x00000251F5F5C910>, root_async_client=<openai.AsyncOpenAI object at 0x00000251F5F5CCD0>, model_name='gpt-4o-mini', temperature=0.5, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ba0b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# 1. From langchain-openai (Partner package)\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# 2. From langchain-core (The new base)\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 3. From langchain (The main logic)\n",
    "from langchain_classic.chains import LLMChain, SequentialChain\n",
    "\n",
    "# 4. From langchain-community (Integrations)\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "from langchain_openai.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b751c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca925c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "you are an expert MCQ maker. Given the above text,it is your job to\\\n",
    "create a quiz of {number}multiple choice questions for {subject} students in {tone} tone.\n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide.\\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "496050d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variable={\"text\",\"number\",\"subject\",\"tone\",\"response_json\"},\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bd4f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=quiz_generation_prompt,\n",
    "    output_key=\"quiz\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e06a12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "you are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "you need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity.\n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "check from an expert English Writer of the above quiz:\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb3049c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(\n",
    "    input_variable={\"subject\",\"quiz\"},\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d36f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=quiz_evaluation_prompt, \n",
    "    output_key=\"review\",verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b213ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain = SequentialChain(chains=[quiz_chain,review_chain],\n",
    "                                         input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],\n",
    "                                         output_variables=[\"quiz\",\"review\"],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "034b506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"C:\\Users\\ADMIN\\mcqgenerator\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b99bb32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ADMIN\\\\mcqgenerator\\\\data.txt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b50708f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "523a60e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions.[1] Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\n",
      "\n",
      "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\n",
      "\n",
      "Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.[3][4]\n",
      "\n",
      "From a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimisation under this framework.\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45c17700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#serialize the python dictionary into a JSON-formatted string\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc526740",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5\n",
    "SUBJECT=\"machine learning\"\n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65aa334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n",
    "\n",
    "#How to setup Token Usage Tracking in LangChain\n",
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\": SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON) \n",
    "        }\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
